# Day 27 - Google 5 Day Course continued - Agents, Google's AI Evaluation API

# Dec 12 2024

### Kaggle/Google Day 3 - Agents

* Kaggle Day 3 - [Agents](https://www.kaggle.com/whitepaper-agents) [(also see this link)](https://drive.google.com/file/d/1oEjiRCTbd54aSdB_eEe3UShxLBWK9xkt/view)
    * [Agent case study - automate ticket to code creation - Woah!!!](https://cloud.google.com/blog/products/ai-machine-learning/regnology-automates-ticket-to-code-with-genai-on-vertex-ai?e=48754805)
        * [ 1. Talk to a database with function calling - manual vs automatic function calls](https://www.kaggle.com/code/markishere/day-3-function-calling-with-the-gemini-api)
        * [ 2. Build an agentic ordering system in LangGraph](https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph/)

* [Google’s AI Evaluation Quality and Explainability](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/enhancing_quality_and_explainability_with_eval.ipynb) - increase creative of generated responses, get 3 to 5 responses. Then evaluate each against one another.

    * Takes the instruction, context and a variable number of corresponding generated responses, and returns the pointwise evaluation metrics for each of the provided metrics. For this example the metrics are Q & A related, however the full list can be found on the website [here](https://cloud.google.com/vertex-ai/generative-ai/docs/models/online-pipeline-services)
    * [Google’s Gen AI evaluation service](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview)  can help you with the following tasks:
        * Model selection: Choose the best pre-trained model for your task based on benchmark results and its performance on your specific data.
        * Generation settings: Tweak model parameters (like temperature) to optimize output for your needs.
        * Prompt engineering: Craft effective prompts and prompt templates to guide the model towards your preferred behavior and responses.
        * Improve and safeguard fine-tuning: Fine-tune a model to improve performance for your use case, while avoiding biases or undesirable behaviors.
        * RAG optimization: Select the most effective Retrieval Augmented Generation (RAG) architecture to enhance performance for your application.
        * Migration: Continuously assess and improve the performance of your AI solution by migrating to newer models when they provide a clear advantage for your specific use case.
        * Translation: Assess the quality of your model's translations.