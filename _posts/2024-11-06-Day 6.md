# Day 6 - Learning Top Down and Bottom Up

(Stanford - Linear Regression) 
* Finished Artificial Intelligence & Machine Learning 2 - [Linear Regression | Stanford CS221: AI (Autumn 2021)](https://www.youtube.com/watch?v=nEWNNt2KmfQ)
    * Went through the video…understood the overall concept
    * Went through it again, made sure I could do the math.
    * At 4:50-ish [here→ Artificial Intelligence & Machine Learning 2 - Linear Regression | Stanford CS221: AI (Autumn 2021)](https://youtu.be/nEWNNt2KmfQ?si=O0fPJKKyTxmRfNtz&t=296) 
        * I had to spend some time understand that I’m multiplying a weighted vector by a feature vector. And that the equations above match what he re-writes them all to by using the dot product of vectors.
        * Went through the math for each step, did the actual math to arrive at each of the numbers
    * Typed out the python too.

(Fast.ai) Started Fast.ai’s [Practical Deep Learning for Coders](https://course.fast.ai/Lessons/lesson1.html) - just the video
* Training is based on having experiences and context – like learning a sport, you have the kids play it and you don’t cover all the rules up front.
* I liked that I understood the Stanford linear regression topic because it helped me understand some of the topics that Fast.ai went through quickly (but they talk a lot about going deeper later)