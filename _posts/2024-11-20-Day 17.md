# Day 17 -  AI/ML Search Algorithms & Optimization Notes (Stanford CS221)

# Nov 20 2024 

(Stanford AI/ML)

## [Search 1 - Dynamic Programming, Uniform Cost Search | Stanford CS221: AI (Autumn 2019) ](https://youtu.be/aIsgJJYrlXk?si=kSbPyRC5fb_lN4XE)

### Transport Problem
* Search - the model first - what are the actions, success function, what is cost function, what is the isEnd function, and what’s the initial state


### Simple Brute Force Algos
* Backtracking search (simplest) - start from initial state, and follow all actions possible, then next set of actions
    * Branching factor is number of branches per state
    * D = depth (little d is when you find a solution at a depth less than max D)
    * **Note: This algo will go through the entire tree!**

| Algo | Cost | Time | Space(memory) |
| ---- | ---- | ---- | ---- |
| Backtracking Search | Any | O(b<sup>D</sup>) | …things I need to store to reach solution => O(D) |
| …  | … | …  | …   |
| Depth First Search (So DFS is great when there are an abundance of solutions.)  | Cost assumed to be zero (it stops once it finds a solution) | O(b<sup>D</sup>) | O(D)  |
| …  | … | …  | …   |
| Breadth First Search  | constant >0 cost, all costs are equal (assumed) but greater than zero | O(b<sup>d</sup>  | O(b<sup>d</sup>)   |
| …  | … | …  | …   |
| DFS-Iterative Deepening (analogy of letting leash getting let out per level after exploring all the levels)  | all costs are equal (assumed) but greater than zero | O(b<sup>d</sup>j  | O(d)   |
* Note: “Any” for costs means that it can also include negative numbers
    * Always exponential time
    * Avoid exponential space with DFS-ID (though solution could be equal)

### Dynamic Programming (backtracking with memoization of past states, potentially exponential savings)

* Min of a { cost (state, a) + FutureCost(s’), where IsEnd=True}
* Future cost depends on current state
    - ** Store previous future costs to re-use later. (if already computed for ‘s’, then return cached answer**
* Key idea: a ‘state’ is  a summary of all the past actions sufficient to choose future actions optimally
* You want bring down state attributes to absolute minimum to bring down computations by as many factors as possible (e.g., N<sup>2</sup> to 2N)

* **LIMITATION - Does not work for Cyclic Graphs**

### Uniform Cost Search ( Dijkstra’s algo)
* Can handled Cyclic Graphs!
* Great for uniformed goal directed agent moving around the search space
* Here is a great video explaining [Uniform Cost Search](https://www.youtube.com/watch?v=dRMvK76xQJI)
* Stanford talked about  
        a) Explored - states we’ve found the optimal path to
        b) Frontier - states we’ve seen, still figure out how to get there cheaply
        c) ..and Unexplored - states we haven’t seen
* Dijkstra will explore all the states in the graph, where this one stops when you hit the solution
* Theorem: correctness - When a state s is popped from the “Frontier” and moved to “Explore”, its priority is PastCost(s), which is the minimum cost to s.

### A* search (A-star search)  - Heuristic or Informed search algorithm
* Here is a great video explaining [A* Search ](https://youtu.be/6TsL96NAZCo?si=iN4dNJqM6vdpH72c)
* Must never overestimate the cost (but can estimate it exactly)
* Similar to UCS but we use cost of path + heuristic of the end node of the path

| Algo | Cost | Time | Space(memory) |
| ---- | ---- | ---- | ---- |
| Dynamic Programming (not w/ cycles)  | any | O(N)  | O(N)   |
| Universal Cost Search  (works w/ cycles) | costs >= 0 | O( n * log * n)  | O( n * log * n)   |
* N total states, n of which are closer than end state
* UCS potentially explores fewer states, but requires more overhead to maintain priority queue
* Assume number of actions per state is constant (independent of n and N)
* “Any” for costs means that it can also include negative numbers
